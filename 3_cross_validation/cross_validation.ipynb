{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliando a qualidade do modelo via cross validation\n",
    "Esse notebook faz parte do material de apoio do tutorial [Introdução ao Scikit-learn - Parte 3: avaliando o modelo via cross validation](http://computacaointeligente.com.br/outros/intro-sklearn-part-3/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_dataset = load_wine()\n",
    "X = wine_dataset['data']\n",
    "y = wine_dataset['target']\n",
    "nome_das_classes = wine_dataset.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o pipeline e executando N vezes\n",
    "Antes de executarmos o *cross-validation* vamos executar o modelos `N` vezes. Mas dessa vez, sempre antes de treinar o modelo, vamos embaralhar a base (perceba que não setamos o parâmetro `random_state`. Por default ele fica como `None`).\n",
    "\n",
    "Nesse experimento, calculamos a média da acurácia. Fica como exercício fazer o mesmo para a matriz de confusão, que foi calculada no parte 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "N = 10\n",
    "acuracias = list()\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "  (\"normalizacao\", MinMaxScaler()),  \n",
    "  (\"KNN\", KNeighborsClassifier(n_neighbors=K))\n",
    "])\n",
    "\n",
    "for i in range(N):\n",
    "    X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "    knn_pipeline.fit(X_treino, y_treino)\n",
    "    ac_i = knn_pipeline.score(X_treino, y_treino)\n",
    "    acuracias.append(ac_i)\n",
    "\n",
    "print(\"- Acurácia:\")\n",
    "print(f\"Media: {round(np.mean(acuracias) * 100, 2)}%\")\n",
    "print(f\"Desvio padrão: {round(np.std(acuracias) * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando cross-validation\n",
    "Ok, agora vamos utilizar cross-validation. Mas primeiro, precisamos do modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipeline = Pipeline(steps=[\n",
    "  (\"normalizacao\", MinMaxScaler()),  \n",
    "  (\"KNN\", KNeighborsClassifier(n_neighbors=3))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando `cross_val_score`\n",
    "Essa função básicamente executa o cross-validation de acordo com o número de *folders* informada via o parâmetro `cv`. Na sequência ela retorna uma métrica de performance para cada folder de teste. Por padrão, essa métrica é a acurácia (para classificação). Mas podemos definir usando o parâmetro `scoring`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracias = cross_val_score(knn_pipeline, X, y, cv=5)\n",
    "print(\"acuracias:\", acuracias)\n",
    "print(\"acuracia final:\", np.mean(acuracias), \"+-\", np.std(acuracias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = cross_val_score(knn_pipeline, X, y, cv=5, scoring=\"f1_macro\")\n",
    "print(\"F1-macros:\", f1s)\n",
    "print(\"F1-macros:\", np.mean(f1s), \"+-\", np.std(f1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando `cross_validate`\n",
    "A principal diferença para o método anterior é que podemos setar várias métricas. Além disso, ele sempre retorn o tempo de `fit` e de `score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_metricas = ['accuracy', 'precision_macro', 'recall_macro']\n",
    "metricas = cross_validate(knn_pipeline, X, y, cv=5, scoring=nome_metricas)\n",
    "for met in metricas:\n",
    "    print(f\"- {met}:\")\n",
    "    print(f\"-- {metricas[met]}\")\n",
    "    print(f\"-- {np.mean(metricas[met])} +- {np.std(metricas[met])}\\n\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando predições via `cross_val_predict`\n",
    "Nesse caso, cada predição será obtida para o conjunto de teste de cada uma das *folders*. Em outras palavras, se `cv=5`, por exemplo, o modelo vai ser treinado para 4 partições e testado em 1, que gera as predições. Ao final das 5 execuções, os resultados são concatenados e retornados.\n",
    "\n",
    "Podemos setar o parametro `method` para escolher qual predição será retornada.\n",
    "\n",
    "**Observação**: os resultados para os dois métodos a seguir podem ser diferentes pois os modelos será retreinado para cada partição (que pode ser diferente). Vamos lidar com isso na sequência usando o `KFold`-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(knn_pipeline, X, y, cv=5)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = cross_val_predict(knn_pipeline, X, y, cv=5, method=\"predict_proba\")\n",
    "print(pred_prob[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo mais controle utilizando `KFold` e  `StratifiedKFold` \n",
    "Ambas funções retornam um *generator* com os indices para selecionar os dados de acordo com o número de *folders* informadas. A principal diferença é que o `StratifiedKFold` estratifica os dados de acordo com as classes. Em outras palavras, ele balanceia a quantidade de amostras de cada classe entre as *folders*. Isso é relevante se o dataset é desbalanceado, algo comum em ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `KFold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folders = 5\n",
    "cross_val = KFold(n_splits=n_folders, shuffle=True, random_state=32)\n",
    "dados_cv = {f\"folder_{f+1}\": {\"treino\": None, \"teste\": None} for f in range(n_folders)}\n",
    "k = 1\n",
    "for indices_treino, indices_teste in cross_val.split(X):\n",
    "    dados_cv[f\"folder_{k}\"][\"treino\"] = (X[indices_treino], y[indices_treino])\n",
    "    dados_cv[f\"folder_{k}\"][\"teste\"] = (X[indices_teste], y[indices_teste])\n",
    "    k+=1\n",
    "print(dados_cv.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As funções `cross_val_predict`, `cross_validate` e `cross_val_predict` aceitam que o parâmetro `cv` seja um inteiro ou um *generator* obtido através da `KFold`-like por exemplo. Isso garante que as partições sejam exatamente as mesmas e evita o problema citado quando usamos `method=\"predict_proba\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(knn_pipeline, X, y, cv=cross_val)\n",
    "pred_prob = cross_val_predict(knn_pipeline, X, y, cv=cross_val, method=\"predict_proba\")\n",
    "print(pred[112])\n",
    "print(pred_prob[112])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos tomar controle do loop de execução do modelo. A gente iniciou esse notebook executando o modelo`n` vezes para partições diferentes de treino e teste. Podemos fazer o mesmo, mas agora usando as *folders*. Isso é que as funções anteriores fazem por trás do pano. Mas por algum motivo, você pode querer controlar esse loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracias = list()\n",
    "for folder in dados_cv:       \n",
    "    knn_pipeline.fit(dados_cv[folder][\"treino\"][0], dados_cv[folder][\"treino\"][1])\n",
    "    ac_i = knn_pipeline.score(dados_cv[folder][\"teste\"][0], dados_cv[folder][\"teste\"][1])\n",
    "    acuracias.append(ac_i)\n",
    "    print(f\"{folder}: {ac_i}\")\n",
    "\n",
    "print(\"\\n- Acurácia das folders:\")\n",
    "print(f\"Media: {round(np.mean(acuracias) * 100, 2)}%\")\n",
    "print(f\"Desvio padrão: {round(np.std(acuracias) * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `StratifiedKFold`\n",
    "A ideia é basicamente a mesma da `KFold`, mas como vai ser estratificado por classe, precisamos passar `y` como parâmetro. Você pode substituir o *generator* obtido aqui para nas células anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folders = 5\n",
    "cross_val_strat = StratifiedKFold(n_splits=n_folders, shuffle=True, random_state=32)\n",
    "dados_cv_strat = {f\"folder_{f+1}\": {\"treino\": None, \"teste\": None} for f in range(n_folders)}\n",
    "k = 1\n",
    "for indices_treino, indices_teste in cross_val_strat.split(X, y):\n",
    "    dados_cv[f\"folder_{k}\"][\"treino\"] = (X[indices_treino], y[indices_treino])\n",
    "    dados_cv[f\"folder_{k}\"][\"teste\"] = (X[indices_teste], y[indices_teste])\n",
    "    k+=1\n",
    "print(dados_cv.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
