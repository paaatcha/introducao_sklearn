{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificando a base de [wine](https://archive.ics.uci.edu/ml/datasets/Wine) usando um KNN\n",
    "Esse notebook faz parte do material de apoio do tutorial [Introdução ao Scikit-learn - Parte 2: iniciando um projeto](http://computacaointeligente.com.br/outros/intro-sklearn-part-2/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_dataset = load_wine()\n",
    "X = wine_dataset['data']\n",
    "y = wine_dataset['target']\n",
    "nome_das_classes = wine_dataset.target_names\n",
    "descricao = wine_dataset['DESCR']\n",
    "print(descricao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processamento\n",
    "- Dividir o dataset em treino e teste\n",
    "- Normalizar os dados usando `MinMaxScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=32)\n",
    "print(f\"Tamanho do conjunto de treino: {len(X_treino)}\")\n",
    "print(f\"Tamanho do conjunto de teste: {len(X_teste)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = MinMaxScaler()\n",
    "normalizador.fit(X_treino)\n",
    "X_treino_norm = normalizador.transform(X_treino)\n",
    "X_teste_norm = normalizador.transform(X_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando e treinando o KNN\n",
    "- Número de vizinhos = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_treino_norm, y_treino)\n",
    "print(f\"Acurácia de treinamento: {knn.score(X_treino_norm, y_treino)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorando alguns métodos da classe `KNeighborsClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_teste_norm) # retorna a classe diretamente\n",
    "y_pred_prob = knn.predict_proba(X_teste_norm) # retorna a probabilidade de cada classe\n",
    "acc_teste = knn.score(X_teste_norm, y_teste)\n",
    "print(f\"Acurácia de teste: {acc_teste}\")\n",
    "print(\"Predições para cada amostra:\")\n",
    "k = 1\n",
    "for l, p in zip(y_pred, y_pred_prob):\n",
    "    print(f\"- Amostra {k}: label = {l} | probabilidades = {p}\")\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relatório de classificação\n",
    "- Obtendo um relatório de classificação com informações de recall, precision, F1-score.\n",
    "- Imprimir a matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatorio = classification_report(y_teste, y_pred, target_names=nome_das_classes)\n",
    "print(\"Relatório de classificação:\")\n",
    "print(relatorio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_conf = confusion_matrix(y_teste, y_pred)\n",
    "print(\"Matriz de confusão:\")\n",
    "print(mat_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empacotando o nosso modelo em um `pipeline`\n",
    "Para fins de aprendizagem, vamos juntar todo o processo de pre-processamento e modelagem dentro de um pipeline. A principal utilidade é simplificar o código e também utilizar-lo para o busca de parâmetros. Como já foi discutido cada passo nas células anteriores, aqui vamos fazer tudo na mesma célula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipeline = Pipeline(steps=[\n",
    "  (\"normalizacao\", MinMaxScaler()),  \n",
    "  (\"KNN\", KNeighborsClassifier(n_neighbors=3))\n",
    "])\n",
    "knn_pipeline.fit(X_treino, y_treino)\n",
    "y_pred = knn_pipeline.predict(X_teste)\n",
    "y_pred_prob = knn_pipeline.predict_proba(X_teste)\n",
    "print(f\"Acurácia de treinamento: {knn_pipeline.score(X_treino, y_treino)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buscando números de vizinhos utilizando `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_busca={\n",
    "  'KNN__n_neighbors': [3, 5, 7]\n",
    "}\n",
    "buscador = GridSearchCV(knn_pipeline, param_grid=param_busca)\n",
    "buscador.fit(X, y)\n",
    "print(\"Melhor K:\", buscador.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame.from_dict(buscador.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando o modelo\n",
    "Na documentação oficial é descrito duas maneiras de persistir modelos da `sklearn`: utilizando `pickle` ou `joblib`. Porém, a mesma recomenda a `joblib` pois ela é mais eficiente para carregar arrays com muitos dados, que é o caso da maioria dos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos iniciar salvando o nosso modelo empacotado dentro do `pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(knn_pipeline, 'knn_pipeline.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para carregar, é igualmente fácil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipeline_carregado = joblib.load('knn_pipeline.joblib') \n",
    "y_pred_prob = knn_pipeline_carregado.predict_proba(X_teste)\n",
    "print(f\"Acurácia de treinamento: {knn_pipeline_carregado.score(X_treino, y_treino)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
